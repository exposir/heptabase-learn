# 苦涩的教训（The Bitter Lesson）：AI 研究 70 年的终极真相

## Rich Sutton 是谁

Rich Sutton，强化学习（Reinforcement Learning）之父，2024 年图灵奖得主（与 Andrew Barto 共同获得）。他写的《Reinforcement Learning: An Introduction》是全球每一个 AI 研究者的圣经。

2019 年 3 月 13 日，他发表了一篇只有千余字的短文——《The Bitter Lesson》。这篇"非论文"却被整个 AI 界视为过去十年最重要的文章之一，因为它用 70 年的历史数据，无情地戳穿了整个学科最不愿面对的真相。

## 核心论点：一句话概括

> **过去 70 年 AI 研究最大的教训是：利用通用计算（搜索和学习）的方法最终总会胜出，而试图将人类知识硬编码进系统的方法最终总会失败。这是一个苦涩的教训，因为研究者们不愿接受自己精心设计的领域知识最终毫无价值。**

## 历史铁证：每一次都是同一个剧本

Sutton 在文中逐一列举了 AI 历史上的关键战场，**每一个都印证同一个 Pattern**：

| 领域       | 人类精心设计（失败方）               | 暴力计算（胜出方）                   | 决定性时刻                |
| ---------- | ------------------------------------ | ------------------------------------ | ------------------------- |
| 国际象棋   | 大师精心编码的开局库、中局评估函数   | Deep Blue 的暴力搜索 + 大规模并行    | 1997 年击败卡斯帕罗夫     |
| 围棋       | 人类棋谱定式、手工特征               | AlphaGo 蒙特卡洛树搜索 + 自我对弈 RL | 2016 年击败李世石         |
| 语音识别   | 语言学家手工设计的音素规则、发音模型 | 统计 HMM → 后被纯深度学习端到端碾压  | 2012 年后深度学习全面接管 |
| 计算机视觉 | SIFT、HOG 等手工特征提取器           | CNN 暴力从像素学特征                 | 2012 年 AlexNet 横空出世  |
| NLP        | 语法树、知识图谱、WordNet            | GPT 纯统计语言模型，暴力预测下一个词 | 2018-2020 年 GPT 系列碾压 |

### 每一次的剧情都完全一样

1. **研究者精心注入人类知识** → 短期表现不错，学术界欢欣鼓舞
2. **另一拨人用通用方法 + 更多计算** → 起初表现不如前者，被嘲笑为"暴力美学"
3. **摩尔定律继续推进，算力持续增长** → 暴力方法开始追上并最终彻底碾压
4. **前者拒绝承认** → 各种辩解（"它只是记忆不是理解"、"这不是真正的智能"）
5. **最终被迫接受** → 整个领域转向

## 为什么叫"苦涩的（Bitter）"

苦涩不在计算本身，**苦涩在于它对人类尊严的打击。**

研究者们花了几十年的职业生涯去理解一个领域（比如语言学、棋类、视觉），把自己最深邃的领域洞察编码进算法里。然后一个什么都"不懂"的统计模型，仅仅因为拥有更多的算力和数据，就把他们毕生心血碾成了废纸。

Sutton 说：**你的聪明才智，在算力面前，是不值钱的。** 这就是"苦涩"的来源——不是技术层面的苦涩，而是存在论层面的苦涩。

## 对我们讨论的意义

如果 The Bitter Lesson 是对的（70 年的证据支持它是对的），它会导出三个不可回避的推论：

### 推论一：AI 发明 Transformer = 必然

发明 Transformer 本质上是"在已知约束下搜索最优架构"——这正是通用方法 + 算力的射程范围。每一个拼图碎片（注意力、残差、归一化）在 2015 年都已经存在。AI 不需要灵光一闪，只需要在庞大的组合空间里，靠暴力穷举找到最优组合。这是 The Bitter Lesson 最经典的应用场景。

### 推论二：AI 发现相对论 = 也是必然

如果你接受"人脑是物理系统 → 它的每一次灵感都是神经元的计算过程 → 物理过程可以被计算复现"这条推理链，那么 The Bitter Lesson 的逻辑就不仅适用于工程问题，也适用于科学发现。

进化论最残酷的真相是：数量和迭代速度，本身就是最高级的智能。

### 推论三：工程化只是捷径，不是前提

我们前面讨论的"Agent 闭环"、"反馈系统"、"搜索空间边界设定"——**这些全是人类精心设计的工程捷径**。它们的作用是加速，让 AI 更快逼近目标。但即使没有这些，只要通用方法 + 足够算力持续堆下去，智能本身就会涌现出发现相对论所需要的一切能力。

这已经在现实中反复发生：

- 没有人"教"GPT-4 写代码 → 从纯文本统计中**涌现**出编程能力
- 没有人"教"GPT-4 做数学推理 → 从 Scale 中**涌现**出逻辑链
- 没有人"教"Sora 物理定律 → 从视频像素中**涌现**出重力和碰撞

## Scaling 的边际递减：The Bitter Lesson 失效了吗？

一个尖锐的追问：GPT-4 到 GPT-4.5，参数量和数据继续暴涨，但能力提升的曲线已经肉眼可见地趋缓。纯靠 Scaling 堆出来的智能增量，边际收益在急速递减。**这是否意味着 The Bitter Lesson 破产了？**

**答案是否定的。** 关键在于区分两个层次：

1. **当前这条具体的 Scaling 路线（更大的 Transformer + 更多的文本数据）确实在撞墙。** 文本数据快被穷尽了，单纯加参数的收益在衰减——这是事实。

2. **但 The Bitter Lesson 说的不是"某一种特定方法要一直 Scale 下去"**，它说的是"通用计算方法这个大类，最终总会赢"。当一条 Scaling 路线撞墙时，历史上每一次的答案都不是"Scaling 失效了"，而是**换一条新的 Scaling 路线继续碾压**：

| 撞墙的路线                      | 接棒的新路线                            |
| ------------------------------- | --------------------------------------- |
| CNN 在图像识别上 Scale 到头     | → Vision Transformer 接棒               |
| LSTM 在语言模型上 Scale 到头    | → Transformer 接棒                      |
| 纯文本预训练 Scale 到头（现在） | → 强化学习（o1 范式）/ 经验学习正在接棒 |

### Sutton 的"第二个苦涩的教训"（2024）

Sutton 本人在 2024 年又提出了一个极其重要的补充：

> 当前的 LLM 可能是一条死胡同，因为它们只从人类已有的文本中学习。真正的下一步是让 AI 从**与世界的直接交互经验**中学习（Era of Experience），而不是从人类写的书里学。

这直接回扣了我们讨论的"2015 年测试"——光读论文不够，必须让 AI 自己动手跑实验、看结果、改代码，在与真实环境的**闭环反馈**中进化。

## The Bitter Lesson 的危险面

但历史也给我们留下了惨痛的警告：**每次有人说"剩下的只是工程问题"的时候，往往正是离下一个寒冬最近的时候。**

- 1960 年代：明斯基说"三五年内 AI 就能做到一切"——然后撞墙，AI 寒冬
- 1980 年代：专家系统大热，"只要规则够多就行"——然后撞墙，又一个寒冬
- 2010 年代初：深度学习爆发，"只要网络够深就行"——然后发现 Scaling 也有墙

Unknown Unknowns（你不知道你不知道什么）是科技预测中最致命的陷阱。The Bitter Lesson 虽然方向正确，但**它不能告诉你中间还隔着多少座看不见的山。**

## 一句话

> **The Bitter Lesson 承诺的不是"某一种方法永远有效"，而是"总会有新的通用方法 + 算力组合出现来突破瓶颈"。方向确定，路径不确定，时间不确定。这就是为什么它既让人振奋，又让人苦涩。**
