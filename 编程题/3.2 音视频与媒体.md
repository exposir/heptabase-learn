<!--
- [INPUT]: HTML5 Video API, MediaSource Extensions (MSE), WebRTC 1.0, Canvas Pixel Manipulation
- [OUTPUT]: 现代多媒体场景的编程题目大纲与实现要求
- [POS]: 编程题/ 复杂场景专题，涵盖流媒体与图形学基础
- [PROTOCOL]: 变更时更新此头部，然后检查 CLAUDE.md
-->

# 3.2 音视频与媒体

Web 媒体技术的演进不仅改变了内容的呈现方式，更在性能与实时性上提出了极高的要求。本专题聚焦多媒体技术的底层原理与实战场景。

---

### 3.2.1 视频播放器封装 ⭐⭐⭐

**要求：** 基于原生 HTML5 Video API，封装一个具备工业级稳定性的播放器核心逻辑。

- **功能清单：**
  - 健壮的**播放状态机**设计（处理 Loading, Playing, Paused, Seeking, Error）
  - 清晰度动态切换逻辑（HLS/DASH 基础原理）
  - 倍速播放与自定义控制条同步
  - 高性能**弹幕渲染**引擎（Canvas vs DOM 方案）
  - 首帧加载优化 (First Frame Optimization)

#### 1. 播放器状态机设计

播放器的本质是一个复杂的同步系统，状态机能有效防止非法操作导致的黑屏或卡顿。

```javascript
// ─────────────────────────────────────────────────
//  VideoPlayerCore — 健壮的播放状态机
// ─────────────────────────────────────────────────

class VideoPlayerCore {
  constructor(videoElement) {
    this.video = videoElement;
    this.state = "IDLE"; // IDLE | LOADING | PLAYING | PAUSED | SEEKING | ERROR
    this._initEvents();
  }

  _setState(newState) {
    if (this.state === newState) return;
    console.log(`[Player] State: ${this.state} -> ${newState}`);
    this.state = newState;
    // 触发 UI 更新
    this.onStateChange?.(newState);
  }

  _initEvents() {
    const v = this.video;
    v.addEventListener("waiting", () => this._setState("LOADING"));
    v.addEventListener("canplay", () => {
      if (this.state === "LOADING") this._setState("PAUSED");
    });
    v.addEventListener("playing", () => this._setState("PLAYING"));
    v.addEventListener("pause", () => this._setState("PAUSED"));
    v.addEventListener("seeking", () => this._setState("SEEKING"));
    v.addEventListener("seeked", () =>
      this._setState(v.paused ? "PAUSED" : "PLAYING"),
    );
    v.addEventListener("error", () => this._setState("ERROR"));
  }

  play() {
    if (this.state === "ERROR") return;
    // 返回 Promise 处理自动播放受限
    return this.video.play().catch((err) => {
      console.warn("Autoplay blocked", err);
      this._setState("PAUSED");
    });
  }

  switchQuality(newUrl) {
    const currentTime = this.video.currentTime;
    const isPaused = this.video.paused;

    this._setState("LOADING");
    this.video.src = newUrl;
    this.video.load();

    // 恢复播放进度的关键：在 canplay 后 seek
    this.video.once("canplay", () => {
      this.video.currentTime = currentTime;
      if (!isPaused) this.play();
    });
  }
}
```

> **本质洞察**：播放器不仅仅是调用 `.play()`，它是对 **Video Pipeline** 状态的镜像。`waiting` 事件揭示了缓冲区 (Buffer) 的干涸，这是区分"用户暂停"与"网络卡顿"的核心逻辑。工业级播放器的稳定性源于对 Buffer 状态的精准预测。

#### 2. 高性能弹幕渲染引擎 (Canvas 方案)

DOM 方案在万级弹幕下会导致重排，Canvas 方案是唯一的生产级选择。

```javascript
// ─────────────────────────────────────────────────
//  DanmakuEngine — 基于 Canvas 的弹幕系统
// ─────────────────────────────────────────────────

class DanmakuEngine {
  constructor(canvas) {
    this.canvas = canvas;
    this.ctx = canvas.getContext("2d");
    this.items = []; // 活跃弹幕
    this.speed = 2; // 基础速度
  }

  add(text, color = "#fff") {
    this.items.push({
      text,
      color,
      x: this.canvas.width,
      y: Math.random() * (this.canvas.height - 20) + 20,
      width: this.ctx.measureText(text).width,
    });
  }

  render() {
    this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
    this.ctx.font = "20px Arial";

    for (let i = this.items.length - 1; i >= 0; i--) {
      const item = this.items[i];
      item.x -= this.speed;

      // 绘制文本
      this.ctx.fillStyle = "rgba(0,0,0,0.5)"; // 描边/阴影增加可读性
      this.ctx.fillText(item.text, item.x + 1, item.y + 1);
      this.ctx.fillStyle = item.color;
      this.ctx.fillText(item.text, item.x, item.y);

      // 移出屏幕后清理
      if (item.x < -item.width) {
        this.items.splice(i, 1);
      }
    }
    requestAnimationFrame(() => this.render());
  }
}
```

---

### 3.2.2 音视频录制 ⭐⭐⭐

**要求：** 使用浏览器原生能力实现多场景的录制功能。

- **核心 API 指标：**
  - `MediaRecorder`: 数据分片存储与编码转换
  - `getUserMedia`: 摄像头与麦克风权限流处理
  - `getDisplayMedia`: 屏幕共享与系统音频采集
  - 录制状态的持久化与异常恢复

#### 1. 屏幕录制与分片存储

```javascript
// ─────────────────────────────────────────────────
//  RecorderManager — 录制管理器
// ─────────────────────────────────────────────────

async function startScreenRecord() {
  // 1. 获取屏幕流
  const stream = await navigator.mediaDevices.getDisplayMedia({
    video: true,
    audio: true,
  });

  const chunks = [];
  const recorder = new MediaRecorder(stream, {
    mimeType: "video/webm;codecs=vp9",
  });

  // 2. 分片收集（解决大文件内存占用问题）
  recorder.ondataavailable = (e) => {
    if (e.data.size > 0) chunks.push(e.data);
  };

  recorder.onstop = () => {
    const blob = new Blob(chunks, { type: "video/webm" });
    const url = URL.createObjectURL(blob);
    // 下载或上传
    console.log("Recorded Video URL:", url);
    stream.getTracks().forEach((track) => track.stop());
  };

  // 每 1s 触发一次 dataavailable，防止事故导致全量丢失
  recorder.start(1000);
  return recorder;
}
```

> **本质洞察**：`MediaRecorder` 的核心考点在 `timeslice` 参数。不传参数时，`onstop` 才会返回整个 Blob（容易 OOM）；传入分片时间，可以实现**边录边传**，这是实现"录制直播"或"异常后恢复"的基础。

---

### 3.2.3 WebRTC 实时通信 ⭐⭐⭐⭐

**要求：** 理解 P2P 通信链路的建立过程，并能够模拟信令交换流程。

- **核心概念：**
  - 信令服务器 (Signaling Server) 的职责与实现
  - ICE/STUN/TURN: 穿透内网的寻址机制
  - 架构选型深度理解：Mesh vs SFU vs MCU
  - 媒体轨迹 (MediaStreamTrack) 的动态伸缩与质量控制

#### 1. P2P 链路建立的核心流程 (SDP 交换)

```javascript
// ─────────────────────────────────────────────────
//  WebRTC-P2P — 极简信令流程模拟
// ─────────────────────────────────────────────────

async function establishConnection() {
  const pc1 = new RTCPeerConnection();
  const pc2 = new RTCPeerConnection();

  // 1. 互相交换 ICE Candidate (内网穿透信息)
  pc1.onicecandidate = (e) => e.candidate && pc2.addIceCandidate(e.candidate);
  pc2.onicecandidate = (e) => e.candidate && pc1.addIceCandidate(e.candidate);

  // 2. 远端流监听
  pc2.ontrack = (e) => {
    document.getElementById("remoteVideo").srcObject = e.streams[0];
  };

  // 3. 采集并添加本地流
  const stream = await navigator.mediaDevices.getUserMedia({ video: true });
  stream.getTracks().forEach((track) => pc1.addTrack(track, stream));

  // 4. Offer/Answer 协商 (SDP 交换)
  const offer = await pc1.createOffer();
  await pc1.setLocalDescription(offer); // 此处触发 ICE 采集
  await pc2.setRemoteDescription(offer);

  const answer = await pc2.createAnswer();
  await pc2.setLocalDescription(answer);
  await pc1.setRemoteDescription(answer);
}
```

**架构方案对比**：

| 方案     | 逻辑                              | 优点                     | 缺点                                  |
| :------- | :-------------------------------- | :----------------------- | :------------------------------------ |
| **Mesh** | 每个人与其他人两两互连            | 无需服务器中转，成本极低 | 3 人以上时，端侧上行带宽与 CPU 爆炸   |
| **SFU**  | 每个人发 1 路，从服务器收 N-1 路  | 性能平衡，支持大规模并发 | 需要中专服务器（如 Mediasoup/Janus）  |
| **MCU**  | 服务器混流，只发给端侧 1 路混合流 | 兼容性极强，端侧压力最小 | 服务器 CPU 消耗极大，无法按需定制布局 |

---

### 3.2.4 图像处理与图形学基础 ⭐⭐⭐

**要求：** 使用 Canvas 或 WebGL 处理底层像素数据。

- **实战场景：**
  - 基于像素矩阵的图片裁剪与动态压缩算法
  - 纯黑白、高斯模糊等经典**滤镜效果**的底层实现
  - EXIF 元数据解析与方位纠正
  - 使用 `OffscreenCanvas` 进行多线程图形渲染优化

#### 1. 核心像素处理：黑白滤镜实现

```javascript
// ─────────────────────────────────────────────────
//  PixelProcessor — 像素级图像处理
// ─────────────────────────────────────────────────

function applyGrayscale(canvas) {
  const ctx = canvas.getContext("2d");
  const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
  const data = imageData.data; // [R1, G1, B1, A1, R2, G2, B2, A2...]

  for (let i = 0; i < data.length; i += 4) {
    // 灰度算法：人眼对绿色的敏感度更高，需加权
    const avg = 0.299 * data[i] + 0.587 * data[i + 1] + 0.114 * data[i + 2];
    data[i] = avg; // R
    data[i + 1] = avg; // G
    data[i + 2] = avg; // B
  }

  ctx.putImageData(imageData, 0, 0);
}
```

> **本质洞察**：图像处理是对 **RGBA 数组** 的线性映射。灰度不是简单的 `(R+G+B)/3`，而是基于视觉生理学的加权平均。更复杂的滤镜（如高斯模糊）则是基于**卷积核 (Convolution Kernel)** 的矩阵运算。

#### 2. 多线程优化：OffscreenCanvas

```javascript
// ── main.js ──
const canvas = document.getElementById("canvas");
const offscreen = canvas.transferControlToOffscreen();
const worker = new Worker("worker.js");
worker.postMessage({ canvas: offscreen }, [offscreen]);

// ── worker.js ──
self.onmessage = (e) => {
  const canvas = e.data.canvas;
  const ctx = canvas.getContext("2d");
  // 在非主线程进行复杂图形绘制，不卡顿 UI
  renderInfinitePattern(ctx);
};
```

---

## 质量指标

- **解码性能**：高分辨率视频下的 CPU/GPU 占用率。
- **实时性**：WebRTC 延迟控制与音画同步 (Lipsync) 效果。
- **内存管理**：处理大文件录制或高清图像时的内存泄漏规避。
