<!--
- [INPUT]: 前端 Blob 操作、Spark-MD5、AbortController、ReadableStream
- [OUTPUT]: 针对 GB 级文件上传与下载的工业级解决方案
- [POS]: 编程题/ 模块的核心专题，解决浏览器环境下的文件 I/O 极限挑战
- [PROTOCOL]: 变更时更新此头部，然后检查 CLAUDE.md
-->

# 2.4 文件处理场景深度剖析

在浏览器环境下处理大文件（GB 级）是前端工程能力的试金石。**文件处理的本质是：如何绕过单线程的内存限制，通过“分治法（分片）”与“流式处理（Streaming）”在不可靠的网络环境中建立稳健的数据通道。**

---

### 2.4.1 大文件分片上传 (Large File Chunk Upload) ⭐⭐⭐⭐

**现象**：直接上传大文件会导致请求超时、内存溢出，且一旦网络波动必须从头再来。
**本质**：利用 `Blob.slice` 将大文件物理切割为多个 Chunk，并发上传，服务端最后进行物理合并。

#### 工业级功能清单与实现
1.  **文件 Hash 计算 (Fingerprinting)**：
    *   **难点**：直接读取 2GB 文件计算 MD5 会导致 UI 卡死。
    *   **方案**：**Worker + 增量计算 (Incremental Hashing)**。利用 `spark-md5` 的 `append` 方法分块读取并计算，不占用主线程。
2.  **断点续传 (Resumable Upload)**：
    *   **方案**：上传前先调接口查询“已上传分片索引列表”。仅上传剩余分片。
3.  **并发控制 (Concurrency Control)**：
    *   **方案**：使用 Promise 池限制并发数（如同时只传 3-6 个分片），防止撑爆浏览器 TCP 连接数。
4.  **秒传 (Instant Upload)**：
    *   **方案**：若服务端已存在该文件的 Hash，直接返回成功，不触发实际上传。
5.  **暂停与恢复**：
    *   **方案**：利用 `AbortController` 信号中断正在进行的 Fetch 请求。

---

### 2.4.2 文件下载场景 (Advanced Download) ⭐⭐⭐

**现象**：点击链接直接下载无法显示进度，且对于大文件容易因内存不足而失败。
**本质**：从“全量加载”转向“流式处理”。

#### 实现要点
*   **进度感知**：利用 `fetch` 的 `response.body.getReader()`。通过 `ReadableStream` 逐步读取 `Uint8Array`，并根据 `Content-Length` 计算百分比。
*   **断点续传下载**：请求头携带 `Range: bytes=start-end`，服务端配合返回 `206 Partial Content`。
*   **流式保存 (Stream Saving)**：使用 `StreamSaver.js` 或 `FileSystemWritableFileStream` 直接将流写入硬盘，不占用浏览器堆内存，从而支持下载 GB 级文件而不崩溃。

---

### 2.4.3 前端 Excel/CSV 解析与导出 ⭐⭐⭐

**现象**：将 10 万行 Excel 一次性读入内存会导致页面崩溃（OOM）。
**本质**：**流式解析与 Worker 隔离。**

#### 解决方案
1.  **解析策略**：使用 `SheetJS` (xlsx) 的流式 API。在 **Web Worker** 中执行解析，避免阻塞渲染。
2.  **数据校验**：在解析过程中按行校验（Streaming Validation），而非全部解析完再校验。
3.  **导出优化**：对于超大规模数据导出，建议使用 CSV 格式以减少库的计算开销，或在后端生成下载链接。

---

## 哲学启示

文件处理遵循 **“不累积 (No Accumulation)”** 原则：数据应像流水一样经过浏览器，而不应像湖泊一样停留在内存里。分片是时间的拆解，流是空间的节约。
